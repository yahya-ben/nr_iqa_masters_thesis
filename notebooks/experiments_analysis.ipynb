{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Bench prompt is performing aesthetic assessment\n",
    "df_llava1_5 = pd.read_csv(\"E:/experiments_results/llava-v1.5-7b_results_20250203_165359.csv\")\n",
    "df_llava1_6 = pd.read_csv(\"E:/experiments_results/llava-v1.6-vicuna-7b_results_20250203_175741.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>dataset</th>\n",
       "      <th>prompt</th>\n",
       "      <th>image_id</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llava-v1.5-7b</td>\n",
       "      <td>KADID10K</td>\n",
       "      <td>prompt1_v1</td>\n",
       "      <td>I01_03_04.png</td>\n",
       "      <td>ER:  \\nRate the quality of the image. ASSISTAN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_name   dataset      prompt       image_id  \\\n",
       "0  llava-v1.5-7b  KADID10K  prompt1_v1  I01_03_04.png   \n",
       "\n",
       "                                     predicted_score  \n",
       "0  ER:  \\nRate the quality of the image. ASSISTAN...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_llava1_5.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ER:  \n",
      "Rate the quality of the image. ASSISTANT: The image is of a helicopter flying in the sky, with a clear blue sky as the backdrop. The helicopter is the main focus of the scene, and it appears to be a large, blue and white aircraft. The sky is cloudless, and the helicopter is flying high, making it a beautiful sight. The image captures the essence of a clear day with a helicopter soaring through the air, creating a sense of freedom and adventure.\n"
     ]
    }
   ],
   "source": [
    "print(df_llava1_5.iloc[0]['predicted_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>dataset</th>\n",
       "      <th>prompt</th>\n",
       "      <th>image_id</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llava-v1.6-vicuna-7b</td>\n",
       "      <td>KADID10K</td>\n",
       "      <td>prompt1_v1</td>\n",
       "      <td>I01_03_04.png</td>\n",
       "      <td>USER: \\nRate the quality of the image. ASSISTA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model_name   dataset      prompt       image_id  \\\n",
       "0  llava-v1.6-vicuna-7b  KADID10K  prompt1_v1  I01_03_04.png   \n",
       "\n",
       "                                     predicted_score  \n",
       "0  USER: \\nRate the quality of the image. ASSISTA...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_llava1_6.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: \n",
      "Rate the quality of the image. ASSISTANT: The image you've provided appears to be of high quality. It captures a clear and detailed view of the helicopter against a backdrop of a blue sky with some clouds. The colors are vibrant, and the image is well-lit, which suggests it was taken during the day under good weather conditions. The focus is sharp, and there are no visible distortions or artifacts that would detract from the overall quality of the image.\n"
     ]
    }
   ],
   "source": [
    "print(df_llava1_6.iloc[0]['predicted_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt1_v1    300\n",
       "prompt1_v3    300\n",
       "prompt2_v1    300\n",
       "prompt2_v2    300\n",
       "prompt3_v1    300\n",
       "prompt3_v2    300\n",
       "prompt4_v1    300\n",
       "Name: prompt, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_llava1_5['prompt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.0\n"
     ]
    }
   ],
   "source": [
    "print(df_llava1_5[(df_llava1_5['prompt'] == \"prompt2_v2\") & (df_llava1_5['dataset'] == \"KADID10K\")].iloc[0]['predicted_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(301):\n",
    "    print(df_llava1_5[(df_llava1_5['prompt'] == \"prompt3_v2\") & (df_llava1_5['dataset'] == \"KADID10K\")].iloc[i]['predicted_score'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
