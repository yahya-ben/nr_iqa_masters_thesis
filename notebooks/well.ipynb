{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cafb05b-9339-45d8-8403-70607b453765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6b09c393-0fd6-4c35-af1b-f6869ed27768",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"~/nr_iqa_masters_thesis/results/llava-v1.6-vicuna-7b_results_20250203_175741.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5d0b11f1-460a-4f85-8f5a-c554b7108d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "KADID10K    1050\n",
       "AGIQA3K     1050\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dataset'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84527037-74db-4442-a9ad-9f11f1d3e5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model_name', 'dataset', 'prompt', 'image_id', 'predicted_score'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3520ba7f-2d0b-4dda-8009-0d0d52524adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 1 examples from each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4394db-32f7-4ad0-822c-359c7ac1885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac7773cc-92e9-4afa-9089-ed47c031ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "535a0050-7cb9-430c-a5e1-d5fef1fb4276",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = ['prompt1_v1', 'prompt1_v3', 'prompt2_v1', 'prompt2_v2', 'prompt3_v1', 'prompt3_v2', 'prompt4_v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c093abc6-112c-4b7b-b4c1-516f81920f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0\n"
     ]
    }
   ],
   "source": [
    "# df[df['prompt'] == \"prompt3_v2\"].head(10)\n",
    "print(df[df['prompt'] == \"prompt2_v2\"].sample(10).iloc[0]['predicted_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7484ada3-77a3-4c7b-a77e-481eb2afe58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funny(text):\n",
    "    return text.str.extract(r'ASSISTANT:\\s*(\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "59bd5a84-eaa3-4e6b-9579-a5a46c7e0c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_v1_kadid_results = list(df[(df['prompt'] == \"prompt2_v1\") & (df['dataset'] == 'KADID10K')]['predicted_score'].values)\n",
    "prompt2_v2_kadid_results = list(df[(df['prompt'] == \"prompt2_v2\") & (df['dataset'] == 'KADID10K')]['predicted_score'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e4cde6-6f21-4094-8315-17b8961a646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not completly reliable prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "085422c8-3f3f-4072-9125-417ddb4d33f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['90.0',\n",
       " '85.0',\n",
       " '90.0',\n",
       " '85.0',\n",
       " '85.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '30.0',\n",
       " '40.0',\n",
       " '85.0',\n",
       " '90.0',\n",
       " '85.0',\n",
       " '90.0',\n",
       " '85.0',\n",
       " '90.0',\n",
       " 'USER: \\nFor the given image, please first detail its perceptual quality in terms of structure and texture preservation, \\n                color and luminance reproduction, noise, contrast, sharpness, and any other low-level distortions. Then, based on the perceptual analysis \\n                of the given image, assign a quality score to the given image. The score must range from 0 to 100, with a higher score denoting better image quality. \\n                Your response must only include a concise description regarding the perceptual quality of the given image, and a score to summarize its perceptual quality of the given image,\\n                while well aligning with the given description. \\n                The response format should be: Description: [a concise description]. Score: [a score]. ASSISTANT: Description: The image showcases a butterfly in a natural setting with green foliage and orange flowers. The butterfly is the main subject, and its wings display a vibrant pattern of colors. The perceptual quality of the image is quite good, with a high level of detail and texture preservation. The colors are rich and accurate, and the luminance is well-reproduced, creating a lifelike representation of the scene. There is minimal noise, and the contrast is high, which enhances the sharpness of the image. The overall quality score for this image is 90, indicating that it is a well-executed photograph with a high level of perceptual quality.',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '20.0',\n",
       " '90.0',\n",
       " '75.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '30.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '85.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '85.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '80.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '85.0',\n",
       " '80.0',\n",
       " '85.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '85.0',\n",
       " '85.0',\n",
       " '90.0',\n",
       " '85.0',\n",
       " '90.0',\n",
       " '85.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '80.0',\n",
       " '90.0',\n",
       " '85.0',\n",
       " '90.0',\n",
       " '40.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '80.0',\n",
       " '80.0',\n",
       " '90.0',\n",
       " '85.0',\n",
       " '85.0',\n",
       " '90.0',\n",
       " '80.0',\n",
       " '90.0',\n",
       " '85.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '85.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '85.0',\n",
       " '85.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " \"USER: \\nFor the given image, please first detail its perceptual quality in terms of structure and texture preservation, \\n                color and luminance reproduction, noise, contrast, sharpness, and any other low-level distortions. Then, based on the perceptual analysis \\n                of the given image, assign a quality score to the given image. The score must range from 0 to 100, with a higher score denoting better image quality. \\n                Your response must only include a concise description regarding the perceptual quality of the given image, and a score to summarize its perceptual quality of the given image,\\n                while well aligning with the given description. \\n                The response format should be: Description: [a concise description]. Score: [a score]. ASSISTANT: Description: The image appears to have good perceptual quality in terms of structure and texture preservation. The leopard's fur is clearly visible with a high level of detail, and the tree bark texture is also well-preserved.\\n\\nColor and luminance reproduction are accurate, with the leopard's fur displaying a natural range of colors and the tree bark showing a range of gray tones.\\n\\nNoise is minimal, and there are no noticeable distortions in the image. The contrast is high, with the leopard's fur standing out against the tree bark.\\n\\nSharpness is good, with the leopard's features and the tree bark textures being well-defined.\\n\\nBased on the perceptual analysis, the image quality score is 90.\",\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '85.0',\n",
       " '90.0',\n",
       " '85.0',\n",
       " '70.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '85.0',\n",
       " '90.0',\n",
       " '20.0',\n",
       " '80.0',\n",
       " '90.0',\n",
       " '50.0',\n",
       " '70.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '80.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '70.0',\n",
       " '90.0',\n",
       " '30.0',\n",
       " '60.0',\n",
       " '60.0',\n",
       " '90.0',\n",
       " '90.0',\n",
       " '85.0',\n",
       " '85.0']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt2_v2_kadid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "12de9ea4-6a36-4269-a4ed-4cb6817a6691",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_v2_kadid_results[11] = 90\n",
    "prompt2_v2_kadid_results[36] = 90\n",
    "prompt2_v2_kadid_results[37] = 95 \n",
    "prompt2_v2_kadid_results[50] = 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "852c8f6f-b555-460a-b439-6b7eecdd9d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_v1_kadid_results = [float(x) for x in prompt2_v1_kadid_results]\n",
    "prompt2_v2_kadid_results = [float(x) for x in prompt2_v2_kadid_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9a419946-e184-463c-a74e-8f976719993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3_v2_kadid_results = list(df[(df['prompt'] == \"prompt3_v2\") & (df['dataset'] == 'KADID10K')]['extracted_number'].values)\n",
    "prompt4_v1_kadid_results = list(df[(df['prompt'] == \"prompt4_v1\") & (df['dataset'] == 'KADID10K')]['extracted_number'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b9c6b763-895a-4d15-8e96-7aab31730d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3_v2_kadid_results = [float(x) for x in prompt3_v2_kadid_results]\n",
    "prompt4_v1_kadid_results = [float(x) for x in prompt4_v1_kadid_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ff741392-7d53-4f9b-a3b0-a43193f929be",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_v1_AGIQA3K_results = list(df[(df['prompt'] == \"prompt2_v1\") & (df['dataset'] == 'AGIQA3K')]['predicted_score'].values)\n",
    "prompt2_v2_AGIQA3K_results = list(df[(df['prompt'] == \"prompt2_v2\") & (df['dataset'] == 'AGIQA3K')]['predicted_score'].values)\n",
    "prompt3_v2_AGIQA3K_results = list(df[(df['prompt'] == \"prompt3_v2\") & (df['dataset'] == 'AGIQA3K')]['extracted_number'].values)\n",
    "prompt4_v1_AGIQA3K_results = list(df[(df['prompt'] == \"prompt4_v1\") & (df['dataset'] == 'AGIQA3K')]['extracted_number'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "14565928-7863-4788-98b1-2b3700557af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 41, 51, 67, 69, 73, 81, 88, 102, 104]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fc28ee32-db83-444e-b016-87b54caea505",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_v2_AGIQA3K_results[8] = 90\n",
    "prompt2_v2_AGIQA3K_results[41] = 85\n",
    "prompt2_v2_AGIQA3K_results[51] = 95\n",
    "prompt2_v2_AGIQA3K_results[67] = 75\n",
    "prompt2_v2_AGIQA3K_results[69] = 90\n",
    "prompt2_v2_AGIQA3K_results[73] = 90\n",
    "# prompt2_v2_AGIQA3K_results[81] = \n",
    "prompt2_v2_AGIQA3K_results[88] = 90\n",
    "prompt2_v2_AGIQA3K_results[102] = 90\n",
    "prompt2_v2_AGIQA3K_results[104] = 95\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "74bd978a-49ac-4566-86d2-1122514cb67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_v1_AGIQA3K_results = [float(x) for x in prompt2_v1_AGIQA3K_results]\n",
    "prompt2_v2_AGIQA3K_results = [float(x) for x in prompt2_v2_AGIQA3K_results]\n",
    "prompt3_v2_AGIQA3K_results = [float(x) for x in prompt3_v2_AGIQA3K_results]\n",
    "prompt4_v1_AGIQA3K_results = [float(x) for x in prompt4_v1_AGIQA3K_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8fa34403-4d84-4601-a302-3094fdcc1392",
   "metadata": {},
   "outputs": [],
   "source": [
    "llava_1_5_results = [prompt2_v1_kadid_results,\n",
    "prompt2_v2_kadid_results,\n",
    "prompt3_v2_kadid_results,\n",
    "prompt4_v1_kadid_results,\n",
    "prompt2_v1_AGIQA3K_results,\n",
    "prompt2_v2_AGIQA3K_results,\n",
    "prompt3_v2_AGIQA3K_results,\n",
    "prompt4_v1_AGIQA3K_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c39e0c19-bb93-415a-b1f9-e0b1b340aaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/nr_iqa_masters_thesis/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "23de129e-baaf-47ed-9c08-1aec55430dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Read the file\n",
    "with open(\"/home/jovyan/nr_iqa_masters_thesis/data/MOS_scores/NR_KADID_sampled_uniform.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Extract image names and their corresponding numbers\n",
    "data = [(match.group(1), float(match.group(2))) for line in lines if (match := re.match(r\"(\\S+\\.png)\\s+([\\d\\.]+)\", line))]\n",
    "\n",
    "# Sort by image name\n",
    "data.sort()\n",
    "\n",
    "# Separate sorted image names and numbers\n",
    "image_names, numbers = zip(*data)\n",
    "\n",
    "# Convert to lists\n",
    "image_names = list(image_names)\n",
    "numbers = list(numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c7c5cc73-6bd9-4529-a900-7ad6d53ebad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.03"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1267af79-adb7-4a1c-b900-267bc9ff38b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "def rescale_to_match(reference_list, target_list):\n",
    "    \"\"\"Rescales target_list to match the min and max scale of reference_list.\"\"\"\n",
    "    min_ref, max_ref = min(reference_list), max(reference_list)\n",
    "    min_target, max_target = min(target_list), max(target_list)\n",
    "\n",
    "    if max_target == min_target:\n",
    "        # Avoid division by zero: all values in target_list are the same\n",
    "        return [np.mean(reference_list)] * len(target_list)\n",
    "    \n",
    "    # Apply min-max scaling\n",
    "    rescaled = [(x - min_target) / (max_target - min_target) * (max_ref - min_ref) + min_ref for x in target_list]\n",
    "    \n",
    "    return rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "15486ba1-99c7-458f-9460-c5e2762d9e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "llava_1_5_results = [\n",
    "prompt2_v1_kadid_results,\n",
    "prompt2_v2_kadid_results,\n",
    "prompt3_v2_kadid_results,\n",
    "prompt4_v1_kadid_results,\n",
    "# prompt2_v1_AGIQA3K_results,\n",
    "# prompt2_v2_AGIQA3K_results,\n",
    "# prompt3_v2_AGIQA3K_results,\n",
    "# prompt4_v1_AGIQA3K_results\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ed83fbd6-08fd-4bb9-8ecf-f7965d807347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation: 0.0468\n",
      "Spearman Correlation: 0.0658\n",
      "Pearson Correlation: 0.1019\n",
      "Spearman Correlation: 0.0979\n",
      "Pearson Correlation: nan\n",
      "Spearman Correlation: nan\n",
      "Pearson Correlation: -0.0748\n",
      "Spearman Correlation: -0.0725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43683/3750509554.py:6: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_corr, _ = pearsonr(numbers, result_rescaled)\n",
      "/tmp/ipykernel_43683/3750509554.py:7: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_corr, _ = spearmanr(numbers, result_rescaled)\n"
     ]
    }
   ],
   "source": [
    "for result in llava_1_5_results:\n",
    "    \n",
    "    # Rescale list_b to match list_a's scale\n",
    "    result_rescaled = rescale_to_match(numbers, result)\n",
    "    \n",
    "    pearson_corr, _ = pearsonr(numbers, result_rescaled)\n",
    "    spearman_corr, _ = spearmanr(numbers, result_rescaled)\n",
    "\n",
    "    print(f\"Pearson Correlation: {pearson_corr:.4f}\")\n",
    "    print(f\"Spearman Correlation: {spearman_corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d7ae26-787a-4d50-81cd-7621feccc1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
